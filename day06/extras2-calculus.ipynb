{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "323decd7-e6b0-4cea-8eb5-8b9ac6071adb",
   "metadata": {},
   "source": [
    "## Machine Learning and Artificial Intelligence \n",
    "Summer High School Academic Program for Engineers (2025)\n",
    "## Calculus Review (just the basics)\n",
    "\n",
    "\n",
    "Overview: \n",
    "* 1. Limits of Sequences and Functions\n",
    "* 2. Derivatives of Single-Variable Functions\n",
    "* 3. Partial Derivatives of Multi-Variable Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e8cc82-2bfa-4931-8dee-34e05bd37d8c",
   "metadata": {},
   "source": [
    "## 1. Limits of Sequences of Functions \n",
    "\n",
    "### Sequences\n",
    "\n",
    "A **sequence** is an ordered list of elements (usually numbers). Each element has an index $a_n$. \n",
    "\n",
    "Often, we can define the next element of a sequence in terms of the previous ones. For example: 2,4,6,8, ... \n",
    "Here, $a_1 = 2$ and each other element $a_{n}$ = $a_{n-1} + 2$. Alternatively, we can define the sequence based on $n$ directly, here $a_n = 2n$. \n",
    "\n",
    "Another example: $a_1 = 1$ and  $a_n = \\frac{1}{2} a_{n-1}$. So we get $1, \\frac{1}{2}, \\frac{1}{4}, \\frac{1}{8}, ...$\n",
    "We can also write this as $a_n = \\frac{1}{2^{n-1}}$\n",
    "\n",
    "These are exampels for **infinite sequences**, but a sequence can also be a **finite sequence**. \n",
    "\n",
    "An infinite sequence may be **divergent**, that is it keeps growing unbounded as $n\\rightarrow \\infty$ or it oscilates between values. \n",
    "It can also be **convergent**, that is it approaches a specific value as $n\\rightarrow \\infty$. For example, $\\lim\\limits_{n\\rightarrow \\infty} = \\frac{1}{2^{n-1}} = 0$ \n",
    "\n",
    "Formally, a converges towards $x$,  ",
    " ",
    " ",
    "that is $\\lim\\limits_{n\\rightarrow \\infty} a_n = x$, if for each $\\epsilon > 0$, there exists a natural number $N > 0$, such that for each $n \\geq N$, we have $|a_n - x| < \\epsilon$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff34bba-7e23-4d09-aed0-15f1fc03296e",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "For functions we are interested in the limit at a specific point $a$: $\\lim\\limits_{x \\rightarrow a} f(x) = L$.\n",
    "\n",
    "As $x$ approaches $a$ from either side, the value $f(x)$ approaches the limit $L$, iff for each $\\epsilon > 0$ there exists a $\\delta > 0$  ",
    " ",
    "such that if $0<|x-a|< \\delta$, then $|f(x)-L|< \\epsilon$.\n",
    "\n",
    "Note that the limit may still exist if $f(a)$ is undefined!\n",
    "\n",
    "<img src=\"https://www.cs.columbia.edu/~bauer/shape/function_limit.png\" width=400px>\n",
    "\n",
    "**One-sided Limit**\n",
    "\n",
    "$\\lim\\limits_{x\\rightarrow a^+} f(x) = L$  means that the limit of $f(x)$ as $x$ approaches $a$ from the right is $L$.  \n",
    "$\\lim\\limits_{x\\rightarrow a^-} f(x) = L$  means that the limit of $f(x)$ as $x$ approaches $a$ from the right is $L$.  \n",
    "\n",
    "For a two-sided limit to exist, both one-sided limits must exist and must be identical.\n",
    "\n",
    "For example, the step function has two one sided limits, but they are not identical. \n",
    "\n",
    "<img src=\"https://www.cs.columbia.edu/~bauer/shape/one_sided__limit.png\" width=400px>\n",
    "\n",
    "**Other Nonexistent Limits**\n",
    "\n",
    "There are other cases in which a two-sided limit does not exist. \n",
    "\n",
    "For example, $\\lim\\limits_{x \\rightarrow 0} \\frac{1}{x}$  \"blows up\" to positive and negative infinity.\n",
    "\n",
    "<img src=\"https://www.cs.columbia.edu/~bauer/shape/hyperbola.png\" width=400px>\n",
    "\n",
    "And $\\lim\\limits_{x \\rightarrow 0} \\sin \\frac{1}{x}$ oscillates between +1 and -1, no matter how close you get to 0. \n",
    "\n",
    "<img src=\"https://www.cs.columbia.edu/~bauer/shape/sin1overx.png\" width=400px>\n",
    "\n",
    "**Continuity**\n",
    "\n",
    "A function $f(x)$ is **continous at c** if $\\lim\\limits_{x\\rightarrow c} f(x)$ exists, $f(c)$ is defined, and $\\lim_{x\\rightarrow c}f(x)=f(c)$.\n",
    "\n",
    "A function is **contious** if it is continous at all real values of $c$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529afaa2-1f0b-4312-a1b7-c3dee18f5d47",
   "metadata": {},
   "source": [
    "## 2. Derivatives of Single Variable Functions\n",
    "\n",
    "### Slope of a Linear Function \n",
    "\n",
    "The idea behind the derivative is that it captures the rate of change of a function $f(x)$, with respect to $x$.\n",
    "\n",
    "Consider the slope $m$ of a linear function $y = f(x) = m x + b$\n",
    "\n",
    "<img src=\"https://www.cs.columbia.edu/~bauer/shape/linear_slope.png\" width=200px>\n",
    "\n",
    "$m = \\frac{\\Delta f}{\\Delta x} = \\frac{f(x + \\Delta{x}) - f(x)}{\\Delta x}$\n",
    "\n",
    "For linear functions, the rate of change is constant across all values of $x$. \n",
    "\n",
    "### Derivative of a function\n",
    "\n",
    "What if the slope is not linear? The rate of change may be different at each point.\n",
    "\n",
    "<img src=\"https://www.cs.columbia.edu/~bauer/shape/xsquared.png\" width=300px>\n",
    "\n",
    "\n",
    "The **derivative** of $f$ is a function describing the rate of change for any point $x$.\n",
    "\n",
    "The derivative of $f$ is defined as \n",
    "\n",
    "$$f'(x) = \\frac{df}{dx} = \\lim\\limits_{x \\rightarrow 0} \\frac{\\Delta f}{\\Delta x}$$\n",
    "$$ = \\lim_{x \\rightarrow 0} \\frac{f(x + \\Delta x) - f(x)}{\\Delta x}$$\n",
    "\n",
    "You can think of the limit as finding better and better estimates for the rate of change by reducing $\\Delta x$ until it is infinitesimally small. \n",
    "\n",
    "<img src=\"https://www.cs.columbia.edu/~bauer/shape/xsquared_limit.png\" width=300px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b855a5b-0456-4248-8449-ceeb7c4a59aa",
   "metadata": {},
   "source": [
    "Example: Derivative of $x^2$\n",
    "\n",
    "$f(x) = x^2$\n",
    "\n",
    "$\\frac{df}{dx} = \\lim\\limits_{x \\rightarrow 0} \\frac{(x + \\Delta x)^2 - x^2}{\\Delta x}$\n",
    "\n",
    "$= \\lim\\limits_{x \\rightarrow 0} \\frac{(x^2 + 2 x \\Delta x + \\Delta x^2) - x^2}{\\Delta x}$\n",
    "\n",
    "$ = \\lim\\limits_{x \\rightarrow 0} \\frac{2 x \\Delta x + \\Delta x^2}{\\Delta x}$\n",
    "\n",
    "$ = \\lim\\limits_{x \\rightarrow 0} 2 x + \\Delta x$ \n",
    "\n",
    "$ = 2x $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3565d494-a92a-4340-bb1b-18f8f4e56fd4",
   "metadata": {},
   "source": [
    "### Some Rules for Derivatives\n",
    "\n",
    "* **Power rule:**  if $f(x) = x^a$ then $\\frac{df}{dx} = a x^{a-1}$\n",
    "\n",
    "  Examples: $\\frac{dx^5}{dx} = 5x^4$  and  $\\frac{d\\sqrt{x}}{dx} =  \\frac{d x^{\\frac{1}{2}}}{dx} = \\frac{1}{2} x ^{-\\frac{1}{2}}$\n",
    "\n",
    "* **Exponential rule:** if $f(x)  = b^x$ then $\\frac{df}{dx} = b^x \\ln b$.  ($\\ln b$ is the natural logaritm of $b$:   $\\ln e^b = b$)\n",
    "\n",
    "  Example: $\\frac{d e^x}{f x} = e^x \\ln e = e^x$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb02c162-2ae1-483a-bd9a-fdaa517c3f03",
   "metadata": {},
   "source": [
    "* **Rule of linearity** (linear combinations): if $f(x) = a g(x)  + b h(x)$, then $\\frac{df}{dx} = a \\frac{dg}{dx} + b \\frac{dh}{dx}$.\n",
    "\n",
    "    Example: $f(x) = 3x^5 + 2x^4 + 3x.$      $\\frac{df}{dx} = 15 x^4 + 8 x^3 + 3$\n",
    "\n",
    "  * **Sum rule**: if $f(x) = g(x) + h(x)$, then $\\frac{df}{dx} = \\frac{dg}{dx} + \\frac{dg}{dx}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ae15f7-2cc0-4e28-aa7a-9e339b5f4401",
   "metadata": {},
   "source": [
    "* **Product rule**: if $f(x) = g(x) \\cdot h(x)$ then $\\frac{df}{dx} = g(x) \\frac{dh}{dx} + h(x) \\frac{dg}{dx}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15c3470-5f82-4732-8310-30c809f84ebb",
   "metadata": {},
   "source": [
    "* **Quotient rule:** if $f(x) = \\frac{g(x)}{h(x)}$ then $\\frac{df}{dx} = \\frac{h(x) \\frac{dg}{dx} - g(x) \\frac{dh}{dx}}{h(x)^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2880b76d-a6dd-48c1-b071-9320d450d812",
   "metadata": {},
   "source": [
    "### The Chain Rule\n",
    "\n",
    "We will look at the chain rule in detail because of its importance for the backpropagation algorithm in neural networks.\n",
    "\n",
    "Consider the case of **function composition**: $f(x) = h(g(x)) = (h \\circ g)(x)$. The function $h$ is applied to the output of function $g$. \n",
    "\n",
    "Note that composition is different from just multiplying the output of the two functions. \n",
    "For example, if $g(x) = x^3$  and $h(x) = x^4$ then $h(x) g(x) = x^4 x^3 = x^7$.\n",
    "But $h(g(x)) = (x^3)^4 = x^{12}$.\n",
    "\n",
    "* The **Chain Rule** says: If $f(x) = h(g(x))$ then $\\frac{df}{dx} = \\frac{dh}{dg} \\frac{dg}{x}$\n",
    "\n",
    "To see why, consider that each change in $x$ causes a change in $y=g(x)$, and each change in $y$ causes a change in $z=h(g(x))$.\n",
    "\n",
    "<img src=\"https://www.cs.columbia.edu/~bauer/shape/chain_rule.png\" width=600px>\n",
    "\n",
    "We can therefore factor the derivative into the two changes: \n",
    "\n",
    "$\\lim\\limits_{x \\rightarrow 0}\\frac{\\Delta f(x)}{\\Delta x} = \\lim\\limits_{x \\rightarrow 0}\\frac{\\Delta z}{\\Delta x} =  \\lim\\limits_{x \\rightarrow 0}\\frac{\\Delta z}{\\Delta y} \\frac{\\Delta y}{\\Delta x}$\n",
    "\n",
    "Example: $g(x) = x^3$ and $h(x) = x^4$ and  $f(x) = h(g(x))$.\n",
    "\n",
    "$\\frac{df}{dx} = 4(g(x))^3 \\cdot 3x^2 = 4(x^3)^3 \\cdot 3x^2 = 4x^9 3 x^2 = 12 x^{11}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbde21b-ac48-4180-a6b2-b797e8997318",
   "metadata": {},
   "source": [
    "## 3. Multi-variable Functions and Partial Derivatives\n",
    "\n",
    "### Partial Derivatives\n",
    "Assume we have a multi-variable function such as $f(x,y) = x^2 - y^2 + 2x + y$.\n",
    "\n",
    "<img src=\"https://www.cs.columbia.edu/~bauer/shape/saddle_function_plot.png\" width=300px>\n",
    "\n",
    "Instead of the derivative, we now compute the **partial derivatives** of the function with respect to each variable: \n",
    "$ \\frac{\\partial f(x,y)}{\\partial x}$ and $ \\frac{\\partial f(x,y)}{\\partial y}$. \n",
    "We usually just write $\\frac{\\partial f}{\\partial x}$ and $\\frac{\\partial f}{\\partial y}$.\n",
    "\n",
    "In other words, we are asking how does the value of the function change if one of the variables changes, while the other(s) stay constant. \n",
    "One way to think about keeping the variables constant is to imagine slicing the function parallel to the axes. \n",
    "\n",
    "<img src=\"https://www.cs.columbia.edu/~bauer/shape/saddle_function_slice.png\" width=300px>\n",
    "\n",
    "The partial derivative of $f$ w.r.t. $y$  is $$\\frac{\\partial f(x,y)}{\\partial{y}} = \\lim\\limits_{y \\rightarrow 0} \\frac{\\Delta f}{\\Delta y} = \\lim\\limits_{y \\rightarrow 0} \\frac{f(x, y + \\Delta y) - f(x,y)}{\\Delta y}$$\n",
    "\n",
    "Most of the rules for single-variable derivatives work exactly the same, except that we treat all variables but one as constant. \n",
    "\n",
    "For example: \n",
    "if $f(x,y) = x^2 - y^2 + 2x + y$, then\n",
    "\n",
    "$\\frac{\\partial f}{\\partial y} = 2x + 2$ and \n",
    "\n",
    "$\\frac{\\partial f}{\\partial y} = -2y + 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c736b74-003b-42d2-ab8c-3cf0ac7724f6",
   "metadata": {},
   "source": [
    "Another example: \n",
    "if $f(x,y) = x^2 y^2 + xy + y$, then\n",
    "\n",
    "$\\frac{\\partial f}{\\partial x} = 2xy^2 + y$ and \n",
    "\n",
    "$\\frac{\\partial f}{\\partial y} = 2yx^2 + x + 1$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181d20e0-44d1-4ac2-977a-051c5336a079",
   "metadata": {},
   "source": [
    "### Gradients \n",
    "\n",
    "The **gradient** of a multivariable function is a **function valued vector**. \n",
    "\n",
    "$$\\nabla f(x_1, \\ldots x_d) = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_d} \\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff93440-2525-48bc-8065-1cbf1f7faab7",
   "metadata": {},
   "source": [
    "Example: If $f(x,y) = x^2 - y^2 + 2x + y$, then \n",
    "\n",
    "$$\\nabla f = \\begin{bmatrix}2x + 2 \\\\ -2y + 1 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de9d072-16e0-48ee-8368-e5f73df2371b",
   "metadata": {},
   "source": [
    "The gradient describes a **vector field**. For any input point of the function, we can apply the gradient functions and obtain a real-valued vector. This vector describes the direction of the greatest change / steepest ascent of the function. \n",
    "\n",
    "For the example above: \n",
    "$ \\nabla{f}(2,3) = \\begin{bmatrix} 6 \\\\ -5\\end{bmatrix}$\n",
    "<img src=\"https://www.cs.columbia.edu/~bauer/shape/saddle_function_gradient_field.png\" width=400px>\n",
    "\n",
    "In machine learning, we often say \"the gradient of f at (2,3)\" to refer to the value of the gradient vector at that specific point.\n",
    "\n",
    "When $f$ is a scalar valued function applied to a vector, such as $f(\\mathbf{x})$ we often just write the gradient as\n",
    "$\\nabla f(\\mathbf{x}) = \\frac{\\partial f}{\\partial \\mathbf{x}}$. The gradient is the vector of partial derivatives with respect to each component of $\\mathbf{x}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d2d7b1-029c-4640-b84f-e24eaf14345b",
   "metadata": {},
   "source": [
    "### Generalized Chain Rule\n",
    "\n",
    "The generalized chain rule is what makes backpropagation work, so this is an important section. \n",
    "\n",
    "Recall the chain rule for single-variable functions\n",
    "                \n",
    "If $f(x) = h(g(x))$ then $\\frac{df}{dx} = \\frac{dh}{dg} \\frac{dg}{x}$\n",
    "\n",
    "\n",
    "**Composite Function With a Single Input Variable**\n",
    "\n",
    "Now consider the case where f(x,y), where x=g(t)  and y=h(t).\n",
    "\n",
    "<img src=\"https://www.cs.columbia.edu/~bauer/shape/comp_graph_single_var.png\" width=100px>\n",
    "\n",
    "The derivative of $f$ needs to account for all ways in which $f$ changes when $t$ changes. Part of this change is due to the change in $h(t)$ and part is due to the change in $f(t)$. \n",
    "\n",
    "$\\frac{df}{dt} f(g(t), h(t)) = \\frac{\\partial f}{\\partial x} \\frac{dx}{dt} +  \\frac{\\partial f}{\\partial y}\\frac{dy}{dt}$\n",
    "\n",
    "**Generalized Chain Rule**\n",
    "\n",
    "Now assume there are ultiple input variables $t_1, \\ldots, t_n$. \n",
    "\n",
    "Assume we have a function $f(x_1, \\ldots x_m)$. Each of the $x_i = g_i(t_1, \\ldots, t_n)$ is the result of applying some function $g_i$ to the input variables.\n",
    "\n",
    "We can now ask for the partial derivative of $f$ with respect to each $t_i$. \n",
    "\n",
    "$\\frac{\\partial f}{\\partial t_j} = \\frac{\\partial f}{\\partial g_1} \\frac{\\partial g_1}{t_j} + \\frac{\\partial f}{\\partial g_1} \\frac{\\partial g_1}{t_j} + \\cdots + \\frac{\\partial f}{\\partial g_m} \\frac{\\partial g_m}{t_j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a68c3a-d854-4751-9fa1-3438320dbfa7",
   "metadata": {},
   "source": [
    "Example: \n",
    "\n",
    "$f(x,y) = xy$\n",
    "\n",
    "$x = g(a,b) = a+b$\n",
    "\n",
    "$y = h(a,b) = b+1$\n",
    "\n",
    "\n",
    "We can display the function $f$ as a **computation graph**\n",
    "\n",
    "<img src=\"https://www.cs.columbia.edu/~bauer/shape/chain_rule_example1.png\" width=300px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd32799-948f-48a8-b8ba-e6b3c3843ca3",
   "metadata": {},
   "source": [
    "We want to compute $\\frac{\\partial f}{\\partial a}$ and $\\frac{\\partial f}{\\partial b}$..\n",
    "\n",
    "The chain rule tells us that \n",
    "\n",
    "$\\frac{\\partial f}{\\partial a} = \\frac{\\partial f}{\\partial x} \\frac{\\partial x}{\\partial a} + \\frac{\\partial f}{\\partial y} \\frac{\\partial y}{\\partial a} $ \n",
    "\n",
    "and \n",
    "\n",
    "$\\frac{\\partial f}{\\partial b} = \\frac{\\partial f}{\\partial x} \\frac{\\partial x}{\\partial b} + \\frac{\\partial f}{\\partial y} \\frac{\\partial y}{\\partial b} $ \n",
    "\n",
    "So we need \n",
    "\n",
    "$\\frac{\\partial f}{\\partial x} = y$\n",
    "\n",
    "$\\frac{\\partial f}{\\partial y} = x$\n",
    "\n",
    "\n",
    "and (left side)\n",
    "\n",
    "$\\frac{\\partial x}{\\partial a} = 1$\n",
    "\n",
    "$\\frac{\\partial x}{\\partial b} = 1$\n",
    "\n",
    "and (right side)\n",
    "\n",
    "$\\frac{\\partial y}{\\partial b} = 1$\n",
    "and $\\frac{\\partial y}{\\partial a} = 0$ (note: $y$ doesn't depend at all on $a$).\n",
    "\n",
    "Plugging these back in: \n",
    "\n",
    "$\\frac{\\partial f}{\\partial a} = y \\cdot 1 + x \\cdot 0 = y = b+1$ \n",
    "\n",
    "$\\frac{\\partial f}{\\partial b} = x \\cdot 1 + y \\cdot 1 = x + y = (a+b) + (b+1) = 2b + a + 1$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa6e85f-64d3-4d3f-9ebe-fe8bb3441659",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
